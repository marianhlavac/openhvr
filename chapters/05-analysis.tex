\chapter{Analytical evaluation of the system}\label{analysis}

In this chapter, the system components and functionalities are being analyzed.
The functionality definition is preceded by the analysis of the human senses.
Each human sense is evaluated and decided if it is suitable to produce effects
that affect those senses. The results of this analysis are then used for
deciding what kind of effects the application will produce.


The system consists of the following components:


\begin{itemize}
  \itemsep0em
  \item Communication Server
  \item Configurator Tool
  \item Unity Plug-in
\end{itemize}


For each of the listed components, functional and non-functional requirements
were constructed. At the end of this chapter, various communication protocols
are assessed to help pick an appropriate way of communication between devices,
server, and the VR application.


\hypertarget{x-assessment-of-human-senses}{\section{Assessment of human senses}}
To correctly assess all possible suitable effects that can be produced, all 
externally affectable human senses have been listed, and each assessed,
if it is possible and appropriate to produce effects that can affect those senses.


The work is focused primarily on external effects. Inner senses, such as
hunger, thirst, or proprioception (sense of body motion), are neither
easily affectable by the standard electronics, but they also might not be safe
and comfortable for the users. The moral point of view
might also be in the way.

We are taking into consideration following human senses:
Visual~(sight), Auditory~(hearing), Somatosensory~(touch), Olfaction~(smell),
Gustation~(taste), and Equilibrioception~(balance). \\
Somatosensory sense can
be further divided into Mechanoreception~(skin~touch), Nociception (pain), and
Thermoception~(heat). Each of them is assessed more in detail further in this
chapter.


The process of affecting each sense has been evaluated by difficulty,
price, ergonomics, and safety. There might be various reasons why some
effects are not suitable for the use-case of this work.
Each of the senses is evaluated by categorizing into three types of results:


\begin{itemize}
  \itemsep0em

  \item \textbf{Suitable} — it might be appropriate to create effects affecting this sense,

  \item \textbf{Irrelevant} — even though it might be appropriate to affect this sense,
  there are reasons why it will not have any effect,

  \item \textbf{Not Suitable} — affecting such sense is inappropriate.

\end{itemize}


\hypertarget{x-irrelevant:-visual-(sight)}{\subsection{Irrelevant: Visual (sight)}}
Since all VR users are wearing a headset that completely blocks
all visual perceptions from the real world and ``replaces'' them by the visuals
created on the display of the VR headset, visual effects produced externally
will have no effect on the user.


Outside of the scope of this work, there might be an opportunity for experiments
to provide effects for people who are not using the VR headset and are
just watching. Such a situation can happen in VR arcades or simply
just between a group of people, where just one of them is wearing the VR headset.
By creating visual effects in sync with the VR
simulation, others can find watching someone else's experience
more enjoyable and entertaining. Nevertheless, for the time being and purposes
of this work, visual effects are considered as irrelevant.


\hypertarget{x-suitable:-auditory-(hearing)}{\subsection{Suitable: Auditory (hearing)}}
There might be the same argument as for the visuals — the majority of virtual reality headsets are already equipped with
headphones, and if not, users often use own headphones for
enhanced immersion in the virtual reality worlds.
Spatial audio\footnote{Spatial audio is a full sphere surround-sound technique that uses a 
dimensional approach to audio to mimic the way we hear in real life.\,\cite{spaudio}}
makes a real difference and is achieved usually using the headphones.
Surround sound is not typical for current virtual reality systems.

However, there is still one opportunity for enhancing the experience with sound.
It is particularly beneficial while using headphones. The typical frequency
response of headphones is from 20Hz to 20KHz,\,\cite{freqresp} but it is obvious
that lower ranges of frequencies produced by headphones are often much
less powerful and can not create large vibrations that can be felt by a whole
body. This type of effect partially belongs to somatosensory senses, because
lower frequencies can not only be heard but also felt. Creating vibrotactile
effects with bass speakers can simulate large thuds or explosions
happening within the virtual world.

\subsection{Suitable: Direct contact}

Simulating the touch is difficult. There are, for example, many receptors on
human fingers, which helps us feel various structures of solid
objects. We can touch the objects and feel the feedback. By squeezing the
object, we can deduce the object’s rigidity, and all this
information is very difficult to simulate and communicate to users from
virtual to the real world.

Some of the touch simulations are already possible, as explored in chapter~\ref{currentstate}, but all
of them are simulated by wearing various wearable equipment (gloves, suits),
or accessories attached to the user’s body.

Suitable are those machines that can produce effects externally (without an
all-time direct contact with the user), so they do not interfere with the VR
experience and can still create direct contact with the user when required.


\hypertarget{x-suitable:-feeling-of-moving-air}{\subsection{Suitable: Feeling of moving air}}
Humans are overall good at detecting winds and their direction. Our body hair
helps a lot. Moving air around using electronics is also very easy; fans
are specialized devices used primarily for the exact purpose.


Wind effects are very suitable and easily achievable as an effect that can
enhance virtual experiences. They are relatively safe, cheap to produce,
directional, and easily controllable.


\hypertarget{x-not-suitable:-feeling-of-wetness}{\subsection{Not Suitable: Feeling of wetness}}
Another way to cause skin sensations is to make the user feel the humidity.
The ability to disperse water in the room might drastically enhance immersion
in the virtual environment. Imagine standing next to the sea or in the rainy weather
inside of the VR scene.

Inspiration for this comes from these so-called `5D Cinemas' — a business
place (widely popular in shopping malls in the Czech Republic) offering
enhanced cinema experience. It uses a combination of 3D stereoscopic
pictures with various enhancing effects; one of them is a small water jet, 
which squirts small amounts of water to simulate a
situation in the scene of the movie, for example, a water splash.\,\cite{5dcin}


It is important to acknowledge that the environment in those 5D cinemas
is more controlled and ready for such conditions. The guests are not
wearing expensive equipment on their heads, and the equipment is
most probably water-proof, and therefore splashing water in the room will not
pose a risk of damaging the equipment.


In the case of a typical virtual reality setup, none of the equipment is ready
for contact with water or high humidity levels. For example — both the
\emph{Oculus Rift} virtual reality headset and the \emph{Oculus Touch} virtual reality
controllers have maximum operating humidity stated at 95\% RH (non-condensing).
\cite{orhswg}


\hypertarget{x-not-suitable:-nociception-(pain)}{\subsection{Not suitable: Nociception (pain)}}
Pain simulation made with electronic devices is possible. Electric currents can
induce pain of various amounts, depending on the amount of electric current
flowing through the body.
Equipment inducing pain electrically are available for consumers
(e.g., tasers, paralyzers, electric shock toys) and it is possible to
incorporate them to generate pain effects for VR simulation.


While pain simulation might greatly enhance virtual reality immersion
(especially in military simulators or computer games on war topics),
such devices also require direct contact with the user and, again,
it might affect user comfort when using the system and might get in between
when experiencing VR experience and affect it negatively.


However, the main concerns and reasons to discard such effect are the
safety and morality of such a device. Thus, such experiments will not be
a part of this work for obvious reasons, and are considered as not suitable.


\hypertarget{x-suitable:-thermoception-(heat)}{\subsection{Suitable: Thermoception (heat)}}
When kept in safe ranges, heat can help users to get more information about the
current scene in the virtual environment and distinguish between 
various ambient conditions.

The feeling of shining sun or heat coming from a cozy fireplace placed in the
virtual world can be simulated using heating elements placed in the real world.

The only risk relates particularly to safety measures, as heating elements are
a potential fire risk, and securing electronic devices producing heat effects
must be emphasized.


\hypertarget{x-suitable:-olfaction-(smell)}{\subsection{Suitable: Olfaction (smell)}}
To the current date, simulation of smell can be categorized as something unusual
or experimental. There are various attempts to simulate smell with electronic
devices; some projects are directly related to virtual reality technologies.


As researched in chapter~\ref{currentstate} and~\ref{relatedwork},
one approach to solving the problem is based on smell
cartridges that emit the smells by heating them with heating elements.
The main disadvantage of such a system is the need for maintenance — the
cartridges need to be replaced, which might turn up to be costly in the
long-term.


Concluding from the performed research, we still have too little
knowledge of how to simulate any smell precisely, or how to affect our organs
sensing smell. Currently, creating smell effects can be reliably achieved
only by heating perfume cartridges.


Although somewhat limited, such devices can be used for producing a simulation
of virtual world smells.


\hypertarget{x-not-suitable:-gustation-(taste)}{\subsection{Not Suitable: Gustation (taste)}}
Similarly to smell simulation, stimulating taste receptors electronically is
complicated as well. Although experiments can be considered more successful
compared to electronic smell simulation (mainly because of easier access
to taste receptors), it is still an early experiment.\,\cite{stsie}


Even if experiments were advanced and in a usable state, it would
require the user to have some kind of electronic device attached to the user’s
tongue. Such attachment might be uncomfortable for the user, especially when
used for long periods of time. Given the little potential of enhancing virtual
reality with taste, the negative effects will most probably balance out
the positive ones.


We can expect development in this field in the future. Suitable would be a product
that is safe and comfortable for long use and uses wireless
technology. But until such a product exists, working with taste simulation
in the current state is not suitable for the project.


\subsection{Not suitable: Equilibrioception (balance)}
To this date, we do not record any electronic device that could
directly affect body balance and simulate its state.

We know too little about controlling the body balance, and overall,
it might not be a good idea to affect the user’s balance. Losing
balance might result in users falling and damaging the equipment (headset and
controllers) or damaging the equipment in the room around the user.

VR is constantly fighting with user’s balance problems,
affecting balance perceptors could potentially be
counter-productive in efforts to eliminate motion sickness.

Affecting user balance is considered as not suitable.

\newpage


\hypertarget{x-overview}{\subsection{Overview}}
As a result of this assessment, a system for external effects for VR experience
enhancement can focus on four senses stimulation — hearing, touch, heat,
and smell.


For simplicity, this work will be focusing on just two of the mentioned suitable
effects — wind and heat.

\begin{table}[H]
\catcode`\-=12
\centering
\vspace{2em}
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{3}{|l|}{\textbf{Sense}}                                                              & \textbf{Result}   \\ \hline
\multicolumn{3}{|l|}{Visual (sight)}                                                              & Irrelevant        \\ \hline
\multicolumn{3}{|l|}{Auditory (hearing)}                                                          & \textbf{Suitable} \\ \hline
\multirow{4}{*}{Somatosensory} & \multirow{3}{*}{Mechanoreception (skin touch)} & Direct contact  & \textbf{Suitable} \\ \cline{3-4} 
                                &                                                & Moving air      & \textbf{Suitable} \\ \cline{3-4} 
                                &                                                & Wetness, fluids & Not Suitable      \\ \cline{2-4} 
                                & \multicolumn{2}{l|}{Nociception (pain)}                          & Not Suitable      \\ \hline
\multicolumn{3}{|l|}{Thermoception (heat)}                                                        & \textbf{Suitable} \\ \hline
\multicolumn{3}{|l|}{Olfaction (smell)}                                                           & \textbf{Suitable} \\ \hline
\multicolumn{3}{|l|}{Gustation (taste)}                                                           & Not Suitable      \\ \hline
\multicolumn{3}{|l|}{Equilibrioception (balance)}                                                 & Not Suitable      \\ \hline
\end{tabular}
\caption{Overview table of assesment results}
\end{table}

\hypertarget{x-viable-electrical-appliances}{\section{Viable electrical appliances}}
Provided with the senses appropriate to affect, it is now important to determine
which electrical appliances can be used for creating effects that can trigger 
the mentioned senses.

We set categories of effects in the following table, and from now on will
refer to these effects by the category names. The choice of specific appliances
is discussed in chapter~\ref{implementation}.

  \begin{table}[H]
  \catcode`\-=12
  \centering
  \begin{tabular}{|l|l|l|}
  \hline
  \textbf{Sense}                          & \textbf{Category}                    & \textbf{Affectable by}      \\ \hline
  \multirow{3}{*}{Auditory (hearing)}     & \multirow{3}{*}{\textbf{Vibrations}} & Large speakers              \\ \cline{3-3} 
                                          &                                      & Subwoofer speakers          \\ \cline{3-3} 
                                          &                                      & Vibration generators/motors \\ \hline
  Mechanoreception (touch) & \textbf{Wind}                        & Pedestal fans               \\ \hline
  \multirow{2}{*}{Thermoception (heat)}   & \multirow{2}{*}{\textbf{Heat}}       & Heaters                     \\ \cline{3-3} 
                                          &                                      & Infrared heaters            \\ \hline
  Olfaction (smell)                       & \textbf{Smell}                       & Perfume dispensers          \\ \hline
  \end{tabular}
  \caption{Electrical appliances categories corresponding to senses}
  \end{table}

Appliance must be controllable programmatically over a computer network,
to act as a dynamic effect generator.

\pagebreak

There are appliances available on the market labeled as `smart'.
Briefly speaking, it means that the appliance
can connect to other devices wired or wirelessly for data exchange.\,\cite{wisd}
Such devices, in most cases, can send information they collect over
the network (e.g., weather stations collecting weather data, making them readable
on user’s smartphones), or able to listen to commands and perform various
kinds of actions (e.g., turn off a desk lamp, unlock door).

There are two ways to approach the selection of appliances. Either the
appliance can be smart and provide an interface of commands that can be sent, or
it can be a typical appliance connected via `smart wall sockets' — 
smart devices that can turn off the electrical power to appliances.

The main disadvantage of using a specialized smart device is the necessity of
working with different interfaces. There must be explicit
support in the server code for specific products. Devices created by different
manufacturers might behave differently.

The main disadvantage of the smart wall socket is the limitation in
control of the appliances. Fundamentally, the appliance can be either turned on or off.
This approach does not allow to precisely control the fan speeds or the power output
of heaters.

\section{Analysis of the appliances used}\label{analysis:appliances}
According to Table 4.2 and taking into consideration the
options available while working on the project, we will be using \textbf{fans
and infrared heaters}
to create wind currents and sources of heat, respectively.

Fans and infrared heaters will be controlled by a smart wall plug
and will be in two states — off and on. For each of the selected appliance
type, a set of properties will be defined
or measured and set as a `effect device properties' in the configuration
software. Such measurements will be taken as a part of the user testing.

\begin{table}[H]
\centering
\begin{tabular}{|p{6em}|p{20em}|p{6em}|}
\hline
\textbf{Property}        & \textbf{Description}                                                                         & \textbf{Expected values} \\ \hline
Actuation time           & The time the device needs to go from a turned-off state to a turned-on state.                & seconds                  \\ \hline
Directionality and range & The range and direction span of the area in which can be the effect experienced by the user. & seconds                  \\ \hline
\end{tabular}
\caption{Effect device properties}
\end{table}

The fact that the appliances differ by manufacturer, model, and type,
makes the measurements specific to each individual device.
For example, it is expected that the spin-up time
(actuation time) and range of wind effect produced by various pedestal fans
will be different, as such properties heavily depend on the power of the fan.

\pagebreak

For the testing environment built for this work, approximate measures will be
taken, and they will be provided in the configuration software as optional
recommended defaults. Administrators will be allowed
to measure their appliances by themselves and configure the properties with
their measured values.


The system presented in this work focuses more
on accessible hardware, open-source and non-proprietary solutions, and
the opportunity for more people to build their effect system in DIY style.


\section{Configurator tool analysis}\label{analysis:conftool}
Configurator Tool (alternatively `Room Configurator') is a web application that
can be used to input properties of the room and effect devices properties and
connection details.
The application should provide convenient GUI\footnote{Graphical User Interface}
for users to easily configure the system for their room and VR setup.


Through this application, users will define the location, rotation, type, and
additional configuration for each effect device placed in the room. The application
can also be used for various general configurations that might arise from
the implementation process, that could not be mentioned in the analysis.


\subsection{Functional requirements}
\paragraph*{User wants to configure his room for use with OpenHVR system <CFG-F1>}
Before using the OpenHVR system in a new space,
the room properties must be configured with the configurator tool.


\paragraph*{User wants to add an effect device into the room configuration <CFG-F2>}
Each device placed into a room that the user intends to use for producing the effects
must be connected with the communication server, and its type must be specified.
Additionally, more configuration might be required, depending on the type
of the device (e.g., thresholds, relay/channel selection, hardware limitations)


\paragraph*{User wants to define a location of added effect device <CFG-F3>}
Each device in a room that the administrator configured,
must have location and rotation (pose) information.


\paragraph*{User wants to input location information using one of the tracked controller in virtual reality space <CFG-F4>}
Additionally, to input location values, for user convenience,
the application will allow using a tracked controller to input the location at
various places for locating the effect
devices and mapping between the real world coordinate system and virtual
world coordinate system.


\subsection{Non-Functional requirements}

\paragraph*{User interface must be fast and responsive <CFG-N1>}
To provide satisfying user experience, the user interface should be fast and
responsive. The user interface should display loading progress and inform users
about currently ongoing actions.


\paragraph*{User interface must follow WCAG 2.1 <CFG-N2>}
The user interface must follow WCAG 2.1\footnote{Web Content Accessibility 
Guidelines (WCAG) 2.1 \href{https://www.w3.org/TR/WCAG21/}{https://www.w3.org/TR/WCAG21/}}
guidelines to provide an accessible user interface.


\section{Communication Server analysis}\label{analysis:server}

Communication Server is a web server, that acts as an intermediary component,
passing information between the IoT devices and the computer with
running VR application. This server holds data about room configuration,
status, and location of the effect devices and overall status of the system.

It must provide API\footnote{Application Programming Interface} to enable
information exchange between the computer running the simulation and IoT devices.


\subsection{Functional requirements}

\paragraph*{User wants to save a new configuration. <SRV-F1>}
\label{srv-f1}
After creating or editing a configuration in Configurator Tool, the user
want to save his changes and apply the effects.


\paragraph*{Unity plug-in will send information containing instructions for reproducing current scene effects <SRV-F2>}
\label{srv-f2}
Each effect happening inside the VR scene will be described as an effect
instruction. Using such instruction, the plug-in will create a request on the server to
reproduce described effects in the real world.


\paragraph*{Effect devices will expect instructions on how to behave <SRV-F3>}
\label{srv-f3}
All running effect devices will individually expect instructions for their
behavior. The server must receive instructions coming from Unity plug-in (in \hyperref[srv-f2]{SRV-F2})
and decide which devices will receive instructions and what content of the
instruction will be.
Practically speaking, if Unity plug-in asks to blow wind from the northern side of
the room, the server will determine which fans are located on the northern side
and send them instruction to start or stop spinning.

\pagebreak

\subsection{Non-Functional requirements}

\paragraph*{The server should be fast and responsive. <SRV-N1>}
\label{srv-n1}
Server will work with real-time data, and therefore, it should be fast and
responsive. The server should utilize asynchronous code (using threads or 
different methods) to be able handle multiple requests concurrently.

\paragraph*{The server should provide a standardized programming interface (RESTful API). <SRV-N2>}
\label{srv-n2}
To help developers easily integrate the server functionalities with other 
programs, the server will implement a RESTful API to provide more uniform
programming interface. The term `RESTful API' is described more in
Section 4.8.3.


\section{Unity Plug-in analysis}\label{analysis:plugin}

Current VR applications do not provide any standardized way
of gathering detailed environmental information about the simulation.
Most often, such details are not generally simulated by the application
(for example, not all VR applications simulate wind currents or
temperature in the scene).

For providing such information to the OpenHVR system, so that it can
reproduce virtual scene conditions in the real world, a custom Unity plug-in
will be implemented.

This plug-in will interoperate with Unity’s Transforms\footnote{Unity’s built-in components implementing the scene graph and defining location and rotation of the objects.}
to determine the effect location. Thanks to the
componential architecture of the game engine, the plug-in can offer
a component object, that can be attached to any game object.
Developers can then use the component in the same way as they use the other
components.

Plug-in components can be similar to existing Unity components, which
developers are used to. For example — the definition of vibration effect can be
very similar to defining a 3D audio source in Unity. In the same way, 
the developers will be able to fine-tune the effect type and its range.

\begin{figure}[H]{}
  \centering\includegraphics[width=\textwidth]{assets/unity-components.png}
  \caption{Screenshot of Unity componential architecture visible in the Unity Editor UI}
\end{figure}

\begin{figure}[H]{}
  \centering\includegraphics[width=\textwidth]{assets/unity-audio.png}
  \caption{3D Audio source set in a Unity Engine scene; the speaker icon defines 
  the location of the sound source, and the blue sphere around it defines the 
  range of the 3D sound}
  \end{figure}

\pagebreak

\subsection{Functional requirements}

\paragraph*{Developer wants to produce an effect at some location in the game world <PLG-F1>}
\label{plg-f1}
Using the component provided by the Unity plug-in, the developer will attach
a component to any object with a Transform component. The Transform component
will give the location of the effect in the game world. The developer will
set and trigger an effect by sending signals to the effect source component.

\paragraph*{Developer wants to use reference points of existing devices in the game world <PLG-F2>}
\label{plg-f2}
The developer can receive
positions and rotations of effect devices to produce effects in the
game world at better and more accurate positions.
This function will be used in the example app. Location points of
fans will be collected, and one of them will be picked and used to alter
the position of the virtual window (it will help to pick the correct wall position,
including the height of the window).

\subsection{Non-Functional requirements}

\paragraph*{Provided resources will be standardized among the Unity Engine environment <PLG-N1>}
\label{plg-n1}
For the implementation of the plug-in, native tools, UI elements, and properties
will be used to achieve creating an interface between Unity and OpenHVR.
Interface and tools should feel familiar for Unity developers.


\section{OpenHVR System analysis}

Users will often come into contact with the system as a whole. End-users
often cannot distinguish between the specific parts or components. From such
users, specific requirements arise. These requirements are not coupled with
any specific component, but rather imposes requirements on the system as a whole.


\subsection{Non-Functional requirements}

\paragraph*{User wants the effects not affect his virtual reality experience negatively <SYS-N1>}
\label{sys-n1}
OpenHVR should not affect the original virtual reality experience in any
negative way. For example, no such effect, produced by the system, should ever
constrain users from experiencing some parts of the original VR experience.

\paragraph*{OpenHVR should not put excessive pressure on system resources of the computer running VR applications <SYS-N2>}
\label{sys-n2}
Regarding system resources, VR applications are very demanding. It must be
made sure that OpenHVR will not use excessive amounts of system resources,
to keep the VR applications running smoothly.

\paragraph*{Reproduction of the technical setup should not be expensive and accessible <SYS-N3>}
\label{sys-n3}
OpenHVR is focused on being non-expensive. The basic technical setup should be
optimized on price, and consists of commonly available equipment.


\section{Means of communication analysis}

It was established that the effect devices would communicate over a computer network.
There are many network protocols, with different properties. The chapter will
analyze possible communication protocols and tools for communication
between smart devices, web servers, and VR applications.


\hypertarget{x-art-net}{\subsection{Art-Net}}
Firstly let us focus on a protocol that would seem to be the best for controlling
physical devices, such as lights or fans. Art-Net is a network protocol for
the distribution of data over an Ethernet network. It supports the connection of DMX
devices, which are most often used for stage lights. It uses a UDP-based packet
structure.\,\cite{artnet}

Art-Net is mostly used for lighting live performances. The first version,
`Art-Net I', was released in 1998. The latest 4th version released
in September 2016
is called `Art-Net 4'. Art-Net is hence matured and widely used in the
entertainment industry.

Equipment supporting Art-Net is professional-grade, 
built to be very reliable, which raises the price point
by a lot and generally makes them unavailable for a typical consumer.


\hypertarget{x-mqtt}{\subsection{MQTT}}
MQTT is a lightweight messaging protocol for small sensors and mobile devices,
optimized for high-latency or unreliable networks.  It is
based on a publish-subscribe concept, and the messages are sorted into a ``topics'',
devices can subscribe to messages published under a topic, or publish
a message into the topic.\cite{mqtthp}


Considering the fact, that the devices will generally be a smart home
electronics, MQTT might be a good choice, because many of them have built-in
support for MQTT or use MQTT as the primary protocol for communication.


The main disadvantage of MQTT is the unreliability in terms of latency.
It heavily depends on the implementation of MQTT on each of the device and on
the implementation of the MQTT server. The latency range is usually
in tens or hundreds of milliseconds for the most popular implementations,
\cite{mqttlat} which is sufficient, but the unpredictability is making MQTT
less suitable for use with real-time effects.

\pagebreak

\subsection{HTTP (REST)}
The most straightforward way of communication between devices would be to use
HTTP protocol, which is the most widespread protocol used in computer networks
and is used every day by billions of users.\,\cite{httpsrv}


A small disadvantage might be the large versatility of the HTTP protocol. There would be
a need for a standardized API for communication between devices and with the
server. To mitigate this disadvantage, a RESTful API can be designed to provide
the standardized API with expectable results.


REST (REpresentational State Transfer) is an architectural style for developing
web services and their interfaces. It defines constraints and conventions to
offer greater performance, scalability, simplicity, and more uniform interface.
\cite{restdef} ``RESTful'' is API that conforms to the REST architectural style.
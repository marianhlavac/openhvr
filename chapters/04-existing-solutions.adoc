== Existing solutions and Related work

In this chapter, existing similar software and research papers related to this
work are discussed. While the previous chapter discussed the VR haptics in
general and presented the most popular current products and researches, this
chapter will focus more on similar projects that implement winds simulations
or other external effects on the user. It also focuses on similar software
solutions relevant to the configuration tool planned for this work.

=== Related work

One of the research papers, called
"Wind and Warmth in Virtual Reality: Implementation and Evaluation",
showed that it is very similar to this work and chose a similar approach. Two
other projects (VRScooter and Ambiotherm) are of the similar or same topic,
but choosing different approach with different objectives.
The following text is discussing the results of the research.

==== Ambiotherm

Ambiotherm is a project researched by Nimesha Ranasinghe et al. at Keio-NUS
CUTE Center, Interactive & Digital Media Institute, National University of
Singapore. This project presents a prototype of a wearable accessory for virtual
reality headsets attached to the user's head and neck to simulate wind
and heat sources. The control module is communicating over Bluetooth with
a mobile device running the VR simulation.

The accessory is designed for use with mobile VR systems.
The advantage of the accessory is the usage of inexpensive hardware and low power
demands. One limiting factor is the lack of locality of the effects.
It is most apparent on the heat simulation, which can simulate
only ambient temperatures -- since the heat-generating device is
placed on the user's neck, they cannot tell where the heat is coming from.

The accessory is then demonstrated on two VR environments -- hot desert and
snowy mountains. With these environments, a study is performed addressing the
design factors of the acessory and its effect on the user's presence
and immersion in the virtual environment.

==== Wind and Warmth in CAVE at Bielefeld University

CAVE is a virtual reality system presented at SIGGRAPH in 1992.
It is quite popular among universities and research centers, because there are
many kinds of research done using the CAVE. CAVE is a bit different from
usual currently popular VR systems, because it does not utilize
stereoscopic displays attached to the user's head, but rather uses multiple
projectors to project images on all sides of the room, where the
VR experience takes place.

In 2014, at the Faculty of Technology of Bielefield University in Germany,
a group of researchers called "AI Group" presented a research paper, in which
they described a system within the CAVE that can simulate winds
and heat in a room in various locations and directions.

Their results have served as inspiration for creating this work.
However, the equipment used for reproducing the system described in this work
is costly and not easily accessible for consumer users.
It consists of many hardware parts, powerful computers, and multiple
networks and protocols. The fans and lights used are commonly used
for various live performances, such as in theatres or live concerts, and are
also very expensive.

==== VR Scooter

In 2006 L.Deligiannidis and R. J.K. Jacob presented a novel input device called
"VR scooter". This device has vibrotactile feedback generators mounted on itself
and accompanying fans are blowing wind to simulate scooter's motion.

Work concluded that the wind simulation and vibration is a viable travel
mechanism type in VR environments. The study conducted within
the work confirmed the hypothesis that the performance improves when the level of
immersion is increased.

==== Conclusion

It is also important to note that almost none of the mentioned works focused on
creating accessible developer tools to help interested developers to create
content utilizing modern tools, frameworks, and game engines.

=== Configurator tools

To produce haptic effects in real-world mapped to virtual reality worlds,
the room needs to be configured first.
That is why the system described in this work will need a configuration utility.
Software related to room configuration is evaluated, whether it is relevant
to virtual reality, IoT, or none of them. It is focused on user interface and functionalities.
The results of this short research of existing solutions
will provide the input for the upcoming analysis and design.

==== SteamVR Room Setup

SteamVR is runtime software primarily designed for use with headsets made
by Valve Corporation (i.e., HTC Vive, Valve Index). Software is used for
system configuration, status reporting, device management, and provides users
with the user interface in VR <<steamvr>>.

In the Room Setup configuration utility, users are guided through a few steps
in which they can prepare their newly bought VR headset to be used in their
home.

In one particular step (which you can see on the screenshot), the user can see
real-time tracking of his space and location of all tracked devices viewed
from the top on a 2-dimensional plane. Thanks to this visual cue, users can
easily set room size and configure the play-space size and rotation.

More information about SteamVR can be found online at
https://partner.steamgames.com/doc/features/steamvr/info[SteamVR page in Steamworks Documentation].

.Screenshot of room setup in SteamVR Room Setup utility {NAHRADIT VLASTNIM}
image::steamvr-setup-room-scale-9.jpg[]

* The user interface is plain and easy to use, it is trying to be informal
  and entertaining (it's employing characters from the Portal 2 game universe
  footnote:[Game universe refers to a collection of art, characters, story
  or items related to a single or series of computer games.],
  and displays various entertaining animations throughout the process)
* Tracked devices (headset, controllers, and lighthouses
  footnote:[Tracking devices used for locating headset and controllers in space]
  ) are visible in
  real-time on the screen.
* All locations are set using tracked controllers. Users can set play-space
  size by taking their controller in four corners of the room and pressing
  the trigger on the controller in each of the corners.

* The software's purpose is to set just the size of play-space; therefore, it is not
  meant to work with any other tracked devices, third-party hardware, or other elements or
  other things placed in the room.
* There is no ability to see the object's positions in 3D-space, as the visualization is
  on a 2-dimensional plane.

==== Oculus Rift Sensor Setup

Oculus Rift Sensor Setup is a configuration utility from Valve Corporation's
competitor -- Facebook Inc. It is intended for use with their headsets
product line named "Oculus".

Since the Oculus Rift uses a different tracking method (it utilizes infrared cameras),
the configuration utility is slightly different and takes a little more
time to set up correctly.

The cameras positions are displayed on a 2D visualization, similar
to SteamVR Room Setup. The feedback of location is valuable, because the
user configuring the system needs to know how to position the
cameras, to achieve better tracking of the headset and the controllers.

Overall, the configurator utility is very similar to SteamVR's one, though it
is less playful, and configuring the system takes more time (there are more steps
involved).

* The user interface is modern and more formal.
* Tracked devices (headset, controllers, and cameras) are visible in real-time
  on the screen.

* For correct configuration, the configurator requires a strict placement
  of the cameras. The configuration process is known to be frustrating,
  as it sometimes can take quite an amount of time to position the cameras correctly.
* There is no ability to see the object's positions in 3D-space, as the visualization is
  on a 2-dimensional plane.

.Screenshot of Oculus Rift Sensor Setup {NAHRADIT VLASTNIM}
image::oculus-sensor.jpg[]

==== xcape.io

Xcape.io is a software used for automating escape rooms
footnote:[An escape room is a popular entertainment game, where players are locked
in a room, and through puzzles are challenged to escape the room in a time limit.].
Although this software's relevance might seem far away,
the similarity lies in the system's utilization of multiple IoT accessories
connected together to provide the automation. Users can connect various
equipment to it and set their behavior.

The software is using MQTT for communication. It can run a MQTT server and
therefore supports any device that uses MQTT as a communication protocol.

The system can be scripted to perform a variety of tasks. It is available
for free as an open-source project on GitHub.

* The user interface is very simple and bare.
* There is no information about the location of connected devices.
* MQTT allows the connection of various types of devices.
